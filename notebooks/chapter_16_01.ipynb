{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neural Cellular Automata Grafting: Jupyter Notebook**\n",
    "\n",
    "This Jupyter Notebook accompanies the chapter on **Neural Cellular Automata Grafting**. It includes practical examples ranging from basic Neural Cellular Automata (NCA) implementations to more advanced grafting techniques. By following along, you'll gain hands-on experience with NCAs and learn how to implement grafting in Python using PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "## **Table of Contents**\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Setup and Prerequisites](#setup-and-prerequisites)\n",
    "3. [Basic Neural Cellular Automata](#basic-neural-cellular-automata)\n",
    "    - [Defining the NCA Model](#defining-the-nca-model)\n",
    "    - [Training a Simple NCA](#training-a-simple-nca)\n",
    "4. [Visualizing NCA Evolution](#visualizing-nca-evolution)\n",
    "5. [Advanced NCA Grafting Techniques](#advanced-nca-grafting-techniques)\n",
    "    - [Training Multiple NCAs](#training-multiple-ncas)\n",
    "    - [Spatial Grafting](#spatial-grafting)\n",
    "    - [Parameter Grafting](#parameter-grafting)\n",
    "    - [Dynamic Grafting](#dynamic-grafting)\n",
    "6. [Experiments and Exercises](#experiments-and-exercises)\n",
    "7. [Conclusion](#conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "In this notebook, we'll explore Neural Cellular Automata (NCA) and various grafting techniques to combine multiple NCAs. We'll start with a basic NCA implementation and progressively move to more complex examples involving grafting.\n",
    "\n",
    "---\n",
    "\n",
    "## **Setup and Prerequisites**\n",
    "\n",
    "### **1. Install Required Libraries**\n",
    "\n",
    "Ensure you have the necessary Python libraries installed. You can install them using `pip`:\n",
    "\n",
    "```python\n",
    "# Install required libraries\n",
    "!pip install torch torchvision matplotlib numpy tqdm\n",
    "```\n",
    "\n",
    "### **2. Import Libraries**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML\n",
    "from matplotlib import animation\n",
    "```\n",
    "\n",
    "### **3. Check for GPU Availability**\n",
    "\n",
    "Using a GPU can significantly speed up training.\n",
    "\n",
    "```python\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Basic Neural Cellular Automata**\n",
    "\n",
    "### **Defining the NCA Model**\n",
    "\n",
    "We'll start by defining a simple NCA model.\n",
    "\n",
    "```python\n",
    "class NeuralCA(nn.Module):\n",
    "    def __init__(self, channel_n=16, fire_rate=0.5):\n",
    "        super(NeuralCA, self).__init__()\n",
    "        self.channel_n = channel_n\n",
    "        self.fire_rate = fire_rate\n",
    "\n",
    "        # Perception layers\n",
    "        self.perception = nn.Conv2d(channel_n, channel_n * 3, kernel_size=3, padding=1, groups=channel_n, bias=False)\n",
    "        \n",
    "        # Update layers\n",
    "        self.update = nn.Sequential(\n",
    "            nn.Conv2d(channel_n * 3, 128, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, channel_n, kernel_size=1),\n",
    "        )\n",
    "        \n",
    "        # Initialize the perception kernels\n",
    "        with torch.no_grad():\n",
    "            sobel_x = torch.tensor([[1.0, 0.0, -1.0],\n",
    "                                    [2.0, 0.0, -2.0],\n",
    "                                    [1.0, 0.0, -1.0]])\n",
    "            sobel_y = torch.tensor([[1.0, 2.0, 1.0],\n",
    "                                    [0.0, 0.0, 0.0],\n",
    "                                    [-1.0, -2.0, -1.0]])\n",
    "            laplace = torch.tensor([[0.0, 1.0, 0.0],\n",
    "                                    [1.0, -4.0, 1.0],\n",
    "                                    [0.0, 1.0, 0.0]])\n",
    "            kernels = torch.stack([sobel_x, sobel_y, laplace])\n",
    "            kernels = kernels.unsqueeze(1).unsqueeze(1) / 8.0\n",
    "            self.perception.weight.data = kernels.repeat(channel_n, 1, 1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Perception\n",
    "        y = self.perception(x)\n",
    "        \n",
    "        # Update\n",
    "        dx = self.update(y)\n",
    "        \n",
    "        # Stochastic update\n",
    "        mask = (torch.rand_like(x[:, :1, :, :]) <= self.fire_rate).float()\n",
    "        dx = dx * mask\n",
    "        \n",
    "        # Apply the update\n",
    "        x = x + dx\n",
    "        return x\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- **Perception Layer**: Extracts local information using fixed kernels (Sobel and Laplacian filters).\n",
    "- **Update Network**: Computes state updates based on the perceived information.\n",
    "- **Stochastic Update**: Simulates asynchronous cell updates using a random mask.\n",
    "\n",
    "### **Training a Simple NCA**\n",
    "\n",
    "We'll train the NCA to generate a simple pattern, such as a circle.\n",
    "\n",
    "#### **Preparing the Target Image**\n",
    "\n",
    "```python\n",
    "def create_target_circle(size, radius, color):\n",
    "    y, x = np.ogrid[-size/2:size/2, -size/2:size/2]\n",
    "    mask = x**2 + y**2 <= radius**2\n",
    "    img = np.zeros((size, size, 4), dtype=np.float32)\n",
    "    img[mask] = color\n",
    "    return img\n",
    "\n",
    "size = 64\n",
    "target_img = create_target_circle(size, 20, [1.0, 0.0, 0.0, 1.0])  # Red circle\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(target_img)\n",
    "plt.title(\"Target Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "![Target Image](attachment:target_image.png)\n",
    "\n",
    "#### **Defining the Training Loop**\n",
    "\n",
    "```python\n",
    "def train_nca(model, target_img, epochs=5000, lr=2e-3, device='cpu'):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    target = torch.from_numpy(target_img).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "    losses = []\n",
    "\n",
    "    # Initialize the grid\n",
    "    x = torch.zeros(1, model.channel_n, target.shape[2], target.shape[3]).to(device)\n",
    "    x[:, :4, target.shape[2]//2, target.shape[3]//2] = 1.0  # Seed in the center\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        x.requires_grad_(True)\n",
    "        for _ in range(8):\n",
    "            x = model(x)\n",
    "            x = torch.clamp(x, 0.0, 1.0)\n",
    "        loss = F.mse_loss(x[:, :4, :, :], target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return model, x.detach(), losses\n",
    "```\n",
    "\n",
    "#### **Training the Model**\n",
    "\n",
    "```python\n",
    "model = NeuralCA().to(device)\n",
    "model, final_state, losses = train_nca(model, target_img, device=device)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Visualizing NCA Evolution**\n",
    "\n",
    "We'll visualize how the NCA evolves over time to form the target pattern.\n",
    "\n",
    "```python\n",
    "def visualize_evolution(model, steps=200):\n",
    "    # Initialize the grid\n",
    "    x = torch.zeros(1, model.channel_n, size, size).to(device)\n",
    "    x[:, :4, size//2, size//2] = 1.0  # Seed in the center\n",
    "    x_history = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        x = model(x)\n",
    "        x = torch.clamp(x, 0.0, 1.0)\n",
    "        x_history.append(x[:, :4, :, :].detach().cpu().numpy())\n",
    "\n",
    "    # Create animation\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "\n",
    "    for img in x_history[::5]:\n",
    "        im = ax.imshow(img[0].transpose(1, 2, 0))\n",
    "        ims.append([im])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True)\n",
    "    plt.close()\n",
    "    return HTML(ani.to_jshtml())\n",
    "\n",
    "visualize_evolution(model)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "An animation showing the evolution of the NCA from the initial state to the final pattern.\n",
    "\n",
    "---\n",
    "\n",
    "## **Advanced NCA Grafting Techniques**\n",
    "\n",
    "### **Training Multiple NCAs**\n",
    "\n",
    "We'll train a second NCA to generate a different pattern.\n",
    "\n",
    "#### **Creating a Second Target Image**\n",
    "\n",
    "```python\n",
    "target_img2 = create_target_circle(size, 15, [0.0, 0.0, 1.0, 1.0])  # Blue circle\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(target_img2)\n",
    "plt.title(\"Second Target Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "![Second Target Image](attachment:second_target_image.png)\n",
    "\n",
    "#### **Training the Second Model**\n",
    "\n",
    "```python\n",
    "model2 = NeuralCA().to(device)\n",
    "model2, final_state2, losses2 = train_nca(model2, target_img2, device=device)\n",
    "```\n",
    "\n",
    "### **Spatial Grafting**\n",
    "\n",
    "We'll combine the two models by assigning each to different regions of the grid.\n",
    "\n",
    "#### **Implementing Spatial Grafting**\n",
    "\n",
    "```python\n",
    "def graft_models(model1, model2, size, steps, device='cpu'):\n",
    "    # Initialize the grid\n",
    "    x = torch.zeros(1, model1.channel_n, size, size).to(device)\n",
    "    x[:, :4, :, :] = 0.5  # Initial state\n",
    "\n",
    "    # Create masks\n",
    "    mask1 = torch.zeros(1, 1, size, size).to(device)\n",
    "    mask1[:, :, :, :size//2] = 1.0  # Left half\n",
    "    mask2 = 1.0 - mask1  # Right half\n",
    "\n",
    "    x_history = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        x1 = model1(x)\n",
    "        x2 = model2(x)\n",
    "        x = x1 * mask1 + x2 * mask2 + x * (1 - mask1 - mask2)\n",
    "        x = torch.clamp(x, 0.0, 1.0)\n",
    "        x_history.append(x[:, :4, :, :].detach().cpu().numpy())\n",
    "\n",
    "    return x_history\n",
    "\n",
    "x_history_grafted = graft_models(model, model2, size=size, steps=200, device=device)\n",
    "```\n",
    "\n",
    "#### **Visualizing Spatial Grafting**\n",
    "\n",
    "```python\n",
    "def visualize_grafted_evolution(x_history):\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "\n",
    "    for img in x_history[::5]:\n",
    "        im = ax.imshow(img[0].transpose(1, 2, 0))\n",
    "        ims.append([im])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True)\n",
    "    plt.close()\n",
    "    return HTML(ani.to_jshtml())\n",
    "\n",
    "visualize_grafted_evolution(x_history_grafted)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "An animation showing how the two NCAs interact in their respective regions and at the boundary.\n",
    "\n",
    "### **Parameter Grafting**\n",
    "\n",
    "We can combine the parameters of the two models.\n",
    "\n",
    "#### **Averaging Model Parameters**\n",
    "\n",
    "```python\n",
    "def average_parameters(model1, model2):\n",
    "    model_combined = NeuralCA().to(device)\n",
    "    with torch.no_grad():\n",
    "        for p1, p2, pc in zip(model1.parameters(), model2.parameters(), model_combined.parameters()):\n",
    "            pc.copy_((p1 + p2) / 2.0)\n",
    "    return model_combined\n",
    "\n",
    "model_combined = average_parameters(model, model2)\n",
    "```\n",
    "\n",
    "#### **Visualizing Parameter Grafting**\n",
    "\n",
    "```python\n",
    "def visualize_combined_model(model_combined, steps=200):\n",
    "    x = torch.zeros(1, model_combined.channel_n, size, size).to(device)\n",
    "    x[:, :4, size//2, size//2] = 1.0  # Seed in the center\n",
    "    x_history = []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        x = model_combined(x)\n",
    "        x = torch.clamp(x, 0.0, 1.0)\n",
    "        x_history.append(x[:, :4, :, :].detach().cpu().numpy())\n",
    "\n",
    "    # Create animation\n",
    "    fig, ax = plt.subplots()\n",
    "    ims = []\n",
    "\n",
    "    for img in x_history[::5]:\n",
    "        im = ax.imshow(img[0].transpose(1, 2, 0))\n",
    "        ims.append([im])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True)\n",
    "    plt.close()\n",
    "    return HTML(ani.to_jshtml())\n",
    "\n",
    "visualize_combined_model(model_combined)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "An animation showing the behavior of the combined model with averaged parameters.\n",
    "\n",
    "### **Dynamic Grafting**\n",
    "\n",
    "Switch between models during simulation.\n",
    "\n",
    "#### **Implementing Dynamic Grafting**\n",
    "\n",
    "```python\n",
    "def dynamic_grafting(model1, model2, size, steps, switch_step, device='cpu'):\n",
    "    x = torch.zeros(1, model1.channel_n, size, size).to(device)\n",
    "    x[:, :4, size//2, size//2] = 1.0  # Seed in the center\n",
    "    x_history = []\n",
    "\n",
    "    for step in range(steps):\n",
    "        if step < switch_step:\n",
    "            x = model1(x)\n",
    "        else:\n",
    "            x = model2(x)\n",
    "        x = torch.clamp(x, 0.0, 1.0)\n",
    "        x_history.append(x[:, :4, :, :].detach().cpu().numpy())\n",
    "\n",
    "    return x_history\n",
    "\n",
    "x_history_dynamic = dynamic_grafting(model, model2, size=size, steps=200, switch_step=100, device=device)\n",
    "```\n",
    "\n",
    "#### **Visualizing Dynamic Grafting**\n",
    "\n",
    "```python\n",
    "visualize_grafted_evolution(x_history_dynamic)\n",
    "```\n",
    "\n",
    "**Output**:\n",
    "\n",
    "An animation showing how the NCA's behavior changes when switching from one model to another during the simulation.\n",
    "\n",
    "---\n",
    "\n",
    "## **Experiments and Exercises**\n",
    "\n",
    "1. **Modify the Target Images**: Try using different shapes or patterns as target images, such as squares, letters, or more complex drawings.\n",
    "\n",
    "2. **Adjust Fire Rates**: Experiment with different `fire_rate` values in the `NeuralCA` model (e.g., 0.1, 0.9) and observe how it affects the evolution.\n",
    "\n",
    "3. **Create Gradient Masks**: Instead of binary masks, use masks with gradient values to blend updates smoothly between models in spatial grafting.\n",
    "\n",
    "    ```python\n",
    "    # Create a gradient mask\n",
    "    mask1 = torch.linspace(1.0, 0.0, steps=size).unsqueeze(0).unsqueeze(0).unsqueeze(3).repeat(1, 1, 1, size).to(device)\n",
    "    mask2 = 1.0 - mask1\n",
    "    ```\n",
    "\n",
    "4. **Train Combined Models**: After grafting models (especially parameter grafting), continue training the combined model and see if it can learn new patterns or improve existing ones.\n",
    "\n",
    "5. **Extend to 3D NCAs**: Modify the code to work with 3D grids and visualize the results using volumetric rendering techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "\n",
    "In this notebook, we've explored Neural Cellular Automata from basic implementations to advanced grafting techniques. By combining multiple NCAs, we can create complex and dynamic patterns that showcase the power of local interactions leading to emergent global behaviors.\n",
    "\n",
    "Feel free to experiment further, modify the code, and explore new ideas in the fascinating world of NCAs.\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: Make sure to run all the code cells in order to avoid any errors due to undefined variables or missing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
